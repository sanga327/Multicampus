{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression의 의미\n",
    "   binary classiication\n",
    "    \n",
    "## 2. Multinomial \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:3.4184141159057617\n",
      "cost값은:0.3024589717388153\n",
      "cost값은:0.25968268513679504\n",
      "cost값은:0.24960170686244965\n",
      "cost값은:0.2458796203136444\n",
      "cost값은:0.2441100925207138\n",
      "cost값은:0.24307036399841309\n",
      "cost값은:0.24233460426330566\n",
      "cost값은:0.2417345941066742\n",
      "cost값은:0.24119840562343597\n",
      "[1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Regression을 그림으로 알아보자! \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn \n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\")  # warning 무시\n",
    "\n",
    "x,y = mglearn.datasets.make_forge()  #가지고있는 데이터 뽑아다가 우리에게 넘겨줌\n",
    "x  # 실수값 들어있는 2차원 배열\n",
    "y  # 0,1\n",
    "\n",
    "# 먼저 간단하게 scatter(산점도)를 그려보자! \n",
    "# y값이 0인 x를 추출해서 x의 첫번째 컬럼을 x축으로, \n",
    "# x의 두번째 컬럼을 y축으로 scatter 그려보자. \n",
    "blue = x[y==0]\n",
    "orange = x[y==1]\n",
    "\n",
    "plt.scatter(blue[:,0],blue[:,1])  # blue[:,0]: 모든 행, 1열\n",
    "plt.scatter(orange[:,0],orange[:,1])\n",
    "\n",
    "# machine learning(Logistic Regression)\n",
    "# train data set  (test는 넘어가자)\n",
    "train_x_data = x\n",
    "train_y_data = y # y축 지금 1차원 배열\n",
    "train_y_data = y.reshape([-1,1])  # 행은 상관없이 열은 1로 고정하자\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1],dtype=tf.float32)\n",
    "\n",
    "# weight, bias\n",
    "W = tf.Variable(tf.random_normal(shape=[2,1])) #자체적으로 값을 변경시킬 수 있는 함수 variable 이용  # 초기값은 랜덤으로 지정\n",
    "b = tf.Variable(tf.random_normal(shape=[1])) \n",
    "\n",
    "# hypothesis\n",
    "logit = tf.matmul(X,W)+b  \n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# cost function(loss function)\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                             labels=Y))\n",
    "\n",
    "# train\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train = optimizer.minimize(cost)  -> 두번할필요없이 아래처럼 축약해서 사용하자\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습 진행\n",
    "for step in range(3000):\n",
    "    _,cost_val = sess.run([train,cost], feed_dict={X:train_x_data,\n",
    "                                                 Y:train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "\n",
    "# 정확도 측정(accuracy): 95% 이상 나오면 쓸만한 모델\n",
    "# Prediction(예측)\n",
    "result = sess.run(H, feed_dict={X:[[9,4]]})\n",
    "plt.scatter(9,4)\n",
    "\n",
    "\n",
    "\n",
    "## sklearn으로 해보자!\n",
    "model = LogisticRegression()  # 기본 모델 만들기\n",
    "myModel = model.fit(x,y)  # logistic model 학습시키기\n",
    "print(myModel.predict([[9,4]])) \n",
    "mglearn.plots.plot_2d_separator(myModel,\n",
    "                                x,\n",
    "                                fill=False,\n",
    "                                eps=0.5, # eps: 크기\n",
    "                                alpha=0.7)  # alpha: 투명도\n",
    "# 이 선의 아래에 있으면 0으로, 위에 있으면 1로 간주하겠다. \n",
    "# 로지스틱은 이 선을 만들어내는 과정.\n",
    "# linear는 데이터를 잘 설명하는 선 그리는 과정(데이터를 대표하는). \n",
    "# logistic은 0과 1을 구분하는 선을 구하는 과정\n",
    "# 3차원일 경우는? 선이 아니라 면이 될 것 \n",
    "\n",
    "# 주황색 하나, 파랑 하나가 다르게 되어있으나\n",
    "# 저걸 제대로 하려면 과적합의 문제가 발생한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1efa20af4a8>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAARKElEQVR4nO3df4xdZZ3H8fdn265UVLprZ5fadu0SibsrguAEURLDgkEUBOOvYKKC0TRrcKkbo1n8AyvJxjVuVJBEUsG1KIuQyrLlh6v4K2oMmGkpv6xmCatSqdtRpIAWluJ3/7iX7TCd6b0zc6eXPn2/kpt7zvM8c843J53PnJ557jypKiRJB74/GnYBkqTBMNAlqREGuiQ1wkCXpEYY6JLUiIXDOvHSpUtr1apVwzq9JB2QNm3a9OuqGpmqb2iBvmrVKsbGxoZ1ekk6ICX5+XR9PnKRpEYY6JLUCANdkhphoEtSIwx0SWqEgS5Jjehr2mKSnwGPAE8Cu6tqdFJ/gIuB1wO/B86tqs2DLVWSZuf623/JJ7/+Ux54aBcvWLKYD732xbzx2OXN1TCTeeh/W1W/nqbvdcCR3dcrgM913yVpqK6//ZdccN1d7HriSQB++dAuLrjuLoD9Fur7q4ZBPXI5C7iyOm4FliRZNqBjS9KsffLrP/3/IH3Kriee5JNf/2lzNfQb6AV8I8mmJKun6F8O3D9hf1u37WmSrE4ylmRsfHx85tVK0gw98NCuGbUfyDX0G+gnVtVxdB6tnJfk1ZP6M8XX7LUUUlWtq6rRqhodGZnyTxFI0kC9YMniGbUfyDX0FehV9UD3fQfw78Dxk4ZsA1ZO2F8BPDCIAiVpLj702hezeNGCp7UtXrSAD732xc3V0DPQkxya5LlPbQOnAndPGrYReFc6TgB2VtX2gVYqSbPwxmOX8/E3vZTlSxYTYPmSxXz8TS/dr7Nc9lcN6bVIdJIj6NyVQ2dWzL9V1T8l+TuAqrqsO23xUuA0OtMW311V+/xTiqOjo+VfW5SkmUmyafLU8af0nLZYVfcBx0zRftmE7QLOm0uRkqS58ZOiktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNaLvQE+yIMntSW6cou/cJONJtnRf7x1smZKkXnoucDHBGmAr8Lxp+q+pqvfPvSRJ0mz0dYeeZAVwOnD5/JYjSZqtfh+5fAb4MPCHfYx5c5I7k2xIsnLupUmSZqJnoCc5A9hRVZv2MewGYFVVHQ18E1g/zbFWJxlLMjY+Pj6rgiVJU+vnDv1E4MwkPwO+Apyc5MsTB1TVb6rq8e7u54GXT3WgqlpXVaNVNToyMjKHsiVJk/UM9Kq6oKpWVNUq4Gzg21X1joljkiybsHsmnV+eSpL2o5nMcnmaJBcBY1W1ETg/yZnAbuBB4NzBlCdJ6leqaignHh0drbGxsaGcW5IOVEk2VdXoVH1+UlSSGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1Ii+Az3JgiS3J7lxir5nJbkmyb1JbkuyapBFSpJ6m8kd+hqmXyv0PcBvq+pFwKeBT8y1MEnSzPQV6ElWAKcDl08z5CxgfXd7A3BKksy9PElSv/q9Q/8M8GHgD9P0LwfuB6iq3cBO4PmTByVZnWQsydj4+PgsypUkTadnoCc5A9hRVZv2NWyKtr1Wn66qdVU1WlWjIyMjMyhTktRLP3foJwJnJvkZ8BXg5CRfnjRmG7ASIMlC4DDgwQHWKUnqoWegV9UFVbWiqlYBZwPfrqp3TBq2ETinu/2W7pi97tAlSfNn4Wy/MMlFwFhVbQSuAL6U5F46d+ZnD6g+SVKfZhToVfVd4Lvd7QsntD8GvHWQhUmSZsZPikpSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGtHPItGHJPlRkjuS3JPkY1OMOTfJeJIt3dd756dcSdJ0+lmx6HHg5Kp6NMki4AdJvlZVt04ad01VvX/wJUqS+tEz0LuLPT/a3V3UfbkAtCQ9w/T1DD3JgiRbgB3ALVV12xTD3pzkziQbkqyc5jirk4wlGRsfH59D2ZKkyfoK9Kp6sqpeBqwAjk9y1KQhNwCrqupo4JvA+mmOs66qRqtqdGRkZC51S5ImmdEsl6p6CPgucNqk9t9U1ePd3c8DLx9IdZKkvvUzy2UkyZLu9mLgNcBPJo1ZNmH3TGDrIIuUJPXWzyyXZcD6JAvo/AC4tqpuTHIRMFZVG4Hzk5wJ7AYeBM6dr4IlSVNLZxLL/jc6OlpjY2NDObckHaiSbKqq0an6/KSoJDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjehnxaJDkvwoyR1J7knysSnGPCvJNUnuTXJbklXzUexTbrrvJk7dcCpHrz+aUzecyk333TSfp5OkA0I/d+iPAydX1THAy4DTkpwwacx7gN9W1YuATwOfGGyZe9x0302s/eFatv9uO0Wx/XfbWfvDtYa6pINez0Cvjke7u4u6r8nLHJ0FrO9ubwBOSZKBVTnBxZsv5rEnH3ta22NPPsbFmy+ej9NJ0gGjr2foSRYk2QLsAG6pqtsmDVkO3A9QVbuBncDzpzjO6iRjScbGx8dnVfCvfverGbVL0sGir0Cvqier6mXACuD4JEdNGjLV3fhei5VW1bqqGq2q0ZGRkZlXCxx+6OEzapekg8WMZrlU1UPAd4HTJnVtA1YCJFkIHAY8OID69rLmuDUcsuCQp7UdsuAQ1hy3Zj5OJ0kHjH5muYwkWdLdXgy8BvjJpGEbgXO6228Bvl1Ve92hD8LpR5zO2letZdmhywhh2aHLWPuqtZx+xOnzcTpJOmAs7GPMMmB9kgV0fgBcW1U3JrkIGKuqjcAVwJeS3EvnzvzseauYTqgb4JL0dD0DvaruBI6dov3CCduPAW8dbGmSpJnwk6KS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEb0swTdyiTfSbI1yT1J9lq8M8lJSXYm2dJ9XTjVsSRJ86efJeh2Ax+sqs1JngtsSnJLVf140rjvV9UZgy9RktSPnnfoVbW9qjZ3tx8BtgLL57swSdLMzOgZepJVdNYXvW2K7lcmuSPJ15K8ZJqvX51kLMnY+Pj4jIuVJE2v70BP8hzgq8AHqurhSd2bgRdW1THAZ4HrpzpGVa2rqtGqGh0ZGZltzZKkKfQV6EkW0Qnzq6rqusn9VfVwVT3a3b4ZWJRk6UArlSTtUz+zXAJcAWytqk9NM+bw7jiSHN897m8GWagkad/6meVyIvBO4K4kW7ptHwH+AqCqLgPeArwvyW5gF3B2VdU81CtJmkbPQK+qHwDpMeZS4NJBFSVJmjk/KSpJjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ij+lmxaGWS7yTZmuSeJGumGJMklyS5N8mdSY6bn3IlSdPpZ8Wi3cAHq2pzkucCm5LcUlU/njDmdcCR3dcrgM913yVJ+0nPO/Sq2l5Vm7vbjwBbgeWThp0FXFkdtwJLkiwbeLWSpGnN6Bl6klXAscBtk7qWA/dP2N/G3qEvSZpHfQd6kucAXwU+UFUPT+6e4kv2WiQ6yeokY0nGxsfHZ1apJGmf+gr0JIvohPlVVXXdFEO2ASsn7K8AHpg8qKrWVdVoVY2OjIzMpl5J0jT6meUS4Apga1V9apphG4F3dWe7nADsrKrtA6xTktRDP7NcTgTeCdyVZEu37SPAXwBU1WXAzcDrgXuB3wPvHnypkqR96RnoVfUDpn5GPnFMAecNqihJ0sz5SVFJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiP6WYLuC0l2JLl7mv6TkuxMsqX7unDwZUqSeulnCbovApcCV+5jzPer6oyBVCRJmpWed+hV9T3gwf1QiyRpDgb1DP2VSe5I8rUkL5luUJLVScaSjI2Pjw/o1JIkGEygbwZeWFXHAJ8Frp9uYFWtq6rRqhodGRkZwKklSU+Zc6BX1cNV9Wh3+2ZgUZKlc65MkjQjcw70JIcnSXf7+O4xfzPX40qSZqbnLJckVwMnAUuTbAM+CiwCqKrLgLcA70uyG9gFnF1VNW8VS5Km1DPQq+rtPfovpTOtUZI0RH5SVJIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUiJ6BnuQLSXYkuXua/iS5JMm9Se5Mctzgy5T6cOe18OmjYO2Szvud1w67Imm/6ucO/YvAafvofx1wZPe1Gvjc3MuSZujOa+GG82Hn/UB13m8431DXQaVnoFfV94AH9zHkLODK6rgVWJJk2aAKlPryrYvgiV1Pb3tiV6ddOkgM4hn6cuD+Cfvbum17SbI6yViSsfHx8QGcWurauW1m7VKDBhHomaKtphpYVeuqarSqRkdGRgZwaqnrsBUza5caNIhA3wasnLC/AnhgAMeV+nfKhbBo8dPbFi3utEsHiUEE+kbgXd3ZLicAO6tq+wCOK/Xv6LfBGy6Bw1YC6by/4ZJOu3SQWNhrQJKrgZOApUm2AR8FFgFU1WXAzcDrgXuB3wPvnq9ipX06+m0GuA5qPQO9qt7eo7+A8wZWkSRpVvykqCQ1wkCXpEYY6JLUCANdkhqRzu80h3DiZBz4+VBOPnhLgV8Pu4hnCK/FHl6LPbwWe8z1Wrywqqb8ZObQAr0lScaqanTYdTwTeC328Frs4bXYYz6vhY9cJKkRBrokNcJAH4x1wy7gGcRrsYfXYg+vxR7zdi18hi5JjfAOXZIaYaBLUiMM9FlKsjLJd5JsTXJPkjXDrmnYkixIcnuSG4ddy7AlWZJkQ5KfdP+NvHLYNQ1Lkn/ofo/cneTqJIcMu6b9JckXkuxIcveEtj9NckuS/+q+/8mgzmegz95u4INV9dfACcB5Sf5myDUN2xpg67CLeIa4GPjPqvor4BgO0uuSZDlwPjBaVUcBC4Czh1vVfvVF4LRJbf8IfKuqjgS+1d0fCAN9lqpqe1Vt7m4/Qucbdsq1VA8GSVYApwOXD7uWYUvyPODVwBUAVfW/VfXQcKsaqoXA4iQLgWdzEK1oVlXfAx6c1HwWsL67vR5446DOZ6APQJJVwLHAbcOtZKg+A3wY+MOwC3kGOAIYB/61+wjq8iSHDruoYaiqXwL/AvwC2E5nRbNvDLeqofvzp1Z1677/2aAObKDPUZLnAF8FPlBVDw+7nmFIcgawo6o2DbuWZ4iFwHHA56rqWOB3DPC/1QeS7vPhs4C/BF4AHJrkHcOtql0G+hwkWUQnzK+qquuGXc8QnQicmeRnwFeAk5N8ebglDdU2YFtVPfU/tg10Av5g9Brgv6tqvKqeAK4DXjXkmobtf5IsA+i+7xjUgQ30WUoSOs9It1bVp4ZdzzBV1QVVtaKqVtH5hde3q+qgvQurql8B9yd5cbfpFODHQyxpmH4BnJDk2d3vmVM4SH9BPMFG4Jzu9jnAfwzqwD3XFNW0TgTeCdyVZEu37SNVdfMQa9Izx98DVyX5Y+A+DtLF06vqtiQbgM10ZobdzkH0ZwCSXA2cBCxNsg34KPDPwLVJ3kPnB95bB3Y+P/ovSW3wkYskNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY34P3UK3tqsmY6FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Logistic Multinomial로 확장해보자!\n",
    "# x 데이터는 시험 성적과 출석점수\n",
    "# y 데이터는 학점\n",
    "x = np.array([[10,5],[9,5],[5,1],[4,2],[1,3]])\n",
    "y = np.array([[\"A\"],[\"A\"],[\"B\"],[\"B\"],[\"C\"]])\n",
    "\n",
    "plt.scatter(x[0:2,0],x[0:2,1])  # A등급 점찍어보자\n",
    "plt.scatter(x[2:3,0],x[2:3,1]) # B등급 점찍어보자\n",
    "plt.scatter(x[4,0],x[4,1])  # C등급 점찍어보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:18.458879470825195\n",
      "cost값은:1.0329055786132812\n",
      "cost값은:0.6862775683403015\n",
      "cost값은:0.5587778091430664\n",
      "cost값은:0.5118946433067322\n",
      "cost값은:0.46800968050956726\n",
      "cost값은:0.0542457178235054\n",
      "cost값은:0.049010004848241806\n",
      "cost값은:0.04514489695429802\n",
      "cost값은:0.042027201503515244\n",
      "정확도:1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 0108 예제3\n",
    "# train data set\n",
    "# 퀴즈1, 퀴즈2, 퀴즈3, 출석\n",
    "train_x_data = [[10,7,8,5],\n",
    "               [8,8,9,4],\n",
    "               [7,8,2,3],\n",
    "               [6,3,9,3],\n",
    "               [7,5,7,4],\n",
    "               [3,5,6,2],\n",
    "               [2,4,3,1]]\n",
    "\n",
    "# 성적 - one hot encoding\n",
    "train_y_data = [[1,0,0],  # A를 표현한 것\n",
    "               [1,0,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,1,0],\n",
    "               [0,0,1],\n",
    "               [0,0,1]]\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,4], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3], dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([4,3]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) # 우리는 각각의 확률이 아니라 전체의 확률 구해야 하므로 sigmoid 사용 X\n",
    "\n",
    "# cost function - hypothesis가 변경되었으므로 cost함수도 변경될 수 밖에 없음\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(3000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={X : train_x_data,\n",
    "                                                 Y : train_y_data})\n",
    "    if step%300==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "        \n",
    "# Accuracy(정확도)\n",
    "sess.run(H,feed_dict={X:[[10,8,9,5]]})\n",
    "# array([[9.9101710e-01, 8.9828558e-03, 2.5414952e-08]], dtype=float32)\n",
    "# -> A될 확률 0.99, B될확률:.. -> 다 더하면 1\n",
    "# 결과로 나온 값이 y label(0,1,0 등)과 같은가 비교하면 됨.\n",
    "\n",
    "predict = tf.argmax(H,axis=1)  # argmax: 데이터가 있을 때 열방향(한 행에서의) 최대값이 몇번째에 있는지\n",
    "# 가장 값이 큰 곳의 index번호를 return (0,1,2중 하나 return)\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:train_x_data,\n",
    "                                                   Y:train_y_data})))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습문제 \n",
    "\n",
    "## BMI 데이터를 학습한 후 자신의 키와 몸무게를 넣어서 자신의 상태를 확인해보자.\n",
    "\n",
    "- bmi.csv 파일을 이용하여 multinomial 문제를 학습해보자!\n",
    "\n",
    "- label 0: thin\n",
    "- label 1: normal\n",
    "- label 2: fat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:1.2413320541381836\n",
      "cost값은:0.5131834745407104\n",
      "cost값은:0.4122363328933716\n",
      "cost값은:0.3603246808052063\n",
      "cost값은:0.32659435272216797\n",
      "cost값은:0.30220213532447815\n",
      "cost값은:0.2834118604660034\n",
      "cost값은:0.26831701397895813\n",
      "cost값은:0.2558182179927826\n",
      "cost값은:0.24523313343524933\n",
      "정확도:0.3165000081062317\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   # 이상치 확인하기 위한 함수\n",
    "import warnings  # 경고 안보이게\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 경고메시지 출력 X\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# 데이터 불러오기\n",
    "bmi_df = pd.read_csv(\"./data/bmi.csv\", skiprows=3) # 앞의 3줄은 빼고 가져오겠다\n",
    "\n",
    "# # 결측치 확인\n",
    "# bmi_df.isnull().sum()  # 결측치 없음 \n",
    "# # 이상치 확인\n",
    "# plt.boxplot(bmi_df[\"height\"]) # 이상치 없음 \n",
    "# plt.boxplot(bmi_df[\"weight\"]) # 이상치 없음 \n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "# train data와 test data 생성 - 80:20\n",
    "train_num = int(bmi_df.shape[0]*0.8) \n",
    "\n",
    "train_x_data = bmi_df[[\"height\",\"weight\"]][:train_num].values\n",
    "train_x_data = MinMaxScaler().fit_transform(train_x_data)\n",
    "test_x_data = bmi_df[[\"height\",\"weight\"]][train_num:].values \n",
    "test_x_data = MinMaxScaler().fit_transform(test_x_data)\n",
    "\n",
    "train_y_data = bmi_df[\"label\"][:train_num].values.reshape(-1,1)\n",
    "test_y_data = bmi_df[\"label\"][train_num:].values.reshape(-1,1)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,1],dtype=tf.int32)\n",
    "\n",
    "class_num = 3\n",
    "Y_one_hot = tf.one_hot(Y,class_num)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1,class_num])\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([2,3]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) \n",
    "\n",
    "# cost function\n",
    "cost_i = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                    labels=Y_one_hot)\n",
    "cost = tf.reduce_mean(cost_i)\n",
    "\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(10000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={X : train_x_data,\n",
    "                                                 Y : train_y_data})\n",
    "    if step%1000==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "        \n",
    "        \n",
    "predict = tf.argmax(H,axis=1)  # argmax: 데이터가 있을 때 열방향(한 행에서의) 최대값이 몇번째에 있는지\n",
    "# 가장 값이 큰 곳의 index번호를 return (0,1,2중 하나 return)\n",
    "\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                   Y:test_y_data})))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습문제 선생님 답"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost값은:1.3155639171600342\n",
      "cost값은:0.3604184091091156\n",
      "cost값은:0.2834528982639313\n",
      "cost값은:0.24525804817676544\n",
      "cost값은:0.2210853099822998\n",
      "cost값은:0.20393280684947968\n",
      "cost값은:0.1909092664718628\n",
      "cost값은:0.18056564033031464\n",
      "cost값은:0.17208126187324524\n",
      "cost값은:0.16495119035243988\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt   # 이상치 확인하기 위한 함수\n",
    "import warnings  # 경고 안보이게\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 경고메시지 출력 X\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "# 데이터 불러오기\n",
    "bmi_df = pd.read_csv(\"./data/bmi.csv\", skiprows=3) # 앞의 3줄은 빼고 가져오겠다\n",
    "\n",
    "# # 결측치 확인\n",
    "# bmi_df.isnull().sum()  # 결측치 없음 \n",
    "# # 이상치 확인\n",
    "# plt.boxplot(bmi_df[\"height\"]) # 이상치 없음 \n",
    "# plt.boxplot(bmi_df[\"weight\"]) # 이상치 없음 \n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "# train data와 test data 생성 \n",
    "# 정규화 작업\n",
    "scaler= MinMaxScaler()\n",
    "train_num = int(bmi_df.shape[0]*0.8) \n",
    "# scaler.data_max_  # 가지고있는 데이터의 최대값\n",
    "# scaler.data_min_  # 최대, 최소값 가지고 scaling\n",
    "x_data = scaler.fit_transform(bmi_df[[\"height\",\"weight\"]])\n",
    "\n",
    "# 데이터 분할해 x data 생성 - 80:20\n",
    "train_x_data = x_data[:train_num]  # nparray에서 자른 값 ->  뒤의 값이 exclusive 해서 16000개\n",
    "test_x_data = x_data[train_num:]\n",
    "\n",
    "# 학습용, 테스트용 y data 생성 -> one hot encoding\n",
    "# one hot encoding으로 전환하는 방법 2가지\n",
    "# 1. pandas.get_dummies()\n",
    "# 2. tensorflow.one_hot()\n",
    "sess = tf.Session()\n",
    "train_y_data = sess.run(tf.one_hot(bmi_df.loc[:train_num-1,\"label\"], 3)) # 원래 1차원 자료가 one-hot encoding 적용하면 2차원 자료가 된다.\n",
    "# sess.run(tf.one_hot(bmi_df.loc[:train_num-1,\"label\"], 3)).shape # data frame이라 loc 사용하면 뒤부분 inclusive하다 -> train_num -1 빼줘야 함! \n",
    "test_y_data = sess.run(tf.one_hot(bmi_df.loc[train_num:,\"label\"], 3))\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,3],dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([2,3]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([3]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) \n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, cost_val = sess.run([train,cost],feed_dict={X : train_x_data,\n",
    "                                                   Y : train_y_data})\n",
    "    if step%3000==0:\n",
    "        print(\"cost값은:{}\".format(cost_val))\n",
    "      \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.9797499775886536\n"
     ]
    }
   ],
   "source": [
    "# Accuracy(정확도) 측정\n",
    "predict = tf.argmax(H,axis=1)  \n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                   Y:test_y_data})))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fat\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "# prediction_data = [[187,78]]\n",
    "# 예측하기 위해서 다시 scaling한 값 넣어줘야 한다.\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform([[165,80]])\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})[0]\n",
    "\n",
    "if result ==0:\n",
    "    print(\"Thin\")\n",
    "elif result ==1:\n",
    "    print(\"Normal\")\n",
    "else:\n",
    "    print(\"Fat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
