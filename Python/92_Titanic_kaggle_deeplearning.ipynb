{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep learning -Titanic을 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")  # warning 출력 X\n",
    "\n",
    "# 데이터 로딩하기 (train data set loading)\n",
    "test_df = pd.read_csv(\"./data/titanic/test.csv\")\n",
    "train_df = pd.read_csv(\"./data/titanic/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리 ### \n",
    "train_df[\"Embarked\"].fillna(\"S\",inplace=True)\n",
    "\n",
    "train_df[\"Title\"]=train_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")  # +: 1개 이상을 의미  # \\.: 점을 의미함.  \n",
    "  # -> 영문자 나오고 끝에 점찍히는 형태 구해라\n",
    "\n",
    "# Titanic안에 Mr,Miss,Mrs,other을 각각 0,1,2,3으로 변환\n",
    "title_mapping_dict = {\"Mr\":0, \"Miss\":1,\"Mrs\":2,\"Master\":3,\"Dr\":3,\"Rev\":3,\"Col\":3,\"Major\":3,\"Mlle\":3,\n",
    "                      \"Don\":3,\"Jonkheer\":3,\"Countess\":3,\"Lady\":3,\"Mme\":3,\"Ms\":3,\"Sir\":3,\"Capt\":3}\n",
    "train_df[\"Title\"]=train_df[\"Title\"].map(title_mapping_dict)\n",
    "train_df.drop(\"Name\",axis=1,inplace=True)  # drop: 행, 열 지울 수 있음 \n",
    "train_df.drop(\"Ticket\",axis=1,inplace=True)\n",
    "train_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "train_df.drop(\"PassengerId\",axis=1,inplace=True)\n",
    "\n",
    "## 성별 column에 대해 male=0, female=1로 변환\n",
    "sex_mapping_dict = {\"male\":0,\"female\":1}\n",
    "train_df[\"Sex\"]=train_df[\"Sex\"].map(sex_mapping_dict)\n",
    "train_df\n",
    "\n",
    "## Embarked (탑승지역) 컬럼에 대해 S = 0, Q =1, C =2로 변환\n",
    "# -> 그냥 하면 NaN 2개 있기 때문에 결과 실수형으로 나옴.\n",
    "embarked_mapping_dict = {\"S\":0,\"Q\":1,\"C\":2}\n",
    "train_df[\"Embarked\"]=train_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "train_df\n",
    "\n",
    "## Age에는 결측치가 많음! \n",
    "age_mean = train_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = train_df[train_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0])\n",
    "b = train_df[train_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = train_df[train_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = train_df[train_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "train_df[\"Age\"]=result_series.sort_index()\n",
    "\n",
    "\n",
    "## Age에 대해서 binning 처리 (구간으로 나눠서 숫자 mapping시켜서 숫자 이용하기)\n",
    "# 고려해야 할 사항 -> 간격 어떻게 설정할거냐?\n",
    "\n",
    "# Age\n",
    "# 0~20 : 0\n",
    "# 20초과~40살 이하 : 1\n",
    "# 40살 초과~60살 이하 : 2\n",
    "# 60살 초과 : 3\n",
    "train_df.loc[train_df[\"Age\"]<=20,\"Age\"]=0\n",
    "train_df.loc[(train_df[\"Age\"]>20)&(train_df[\"Age\"]<=40),\"Age\"]=1\n",
    "train_df.loc[(train_df[\"Age\"]>40)&(train_df[\"Age\"]<=60),\"Age\"]=2\n",
    "train_df.loc[train_df[\"Age\"]>60,\"Age\"]=3\n",
    "\n",
    "# # Fare도 binning 처리 해보자\n",
    "train_df.loc[train_df[\"Fare\"]<=14,\"Fare\"]=0\n",
    "train_df.loc[(train_df[\"Fare\"]>14)&(train_df[\"Fare\"]<=65),\"Fare\"]=1\n",
    "train_df.loc[(train_df[\"Fare\"]>65),\"Fare\"]=2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train,test data set\n",
    "x_data = train_df.drop(\"Survived\",axis=1,inplace=False).values  # 컬럼삭제, 원본유지 \n",
    "y_data = train_df[\"Survived\"].values.reshape([-1,1])  # 1차원의 array로 나오므로 2차원의 numpy array로 형태 바꿔줘야 함\n",
    "\n",
    "# 80 20나누자\n",
    "train_num = int(train_df.shape[0]*0.8)  # 712개\n",
    "# test_num = train_df.shape[0]-train_num\n",
    "\n",
    "# train,test data set\n",
    "train_x_data = train_df.drop(\"Survived\",axis=1,inplace=False)[:train_num].values  # 컬럼삭제, 원본유지 \n",
    "test_x_data = train_df.drop(\"Survived\",axis=1,inplace=False)[train_num:].values  \n",
    "\n",
    "train_y_data = train_df[\"Survived\"][:train_num].values.reshape([-1,1])  # 1차원의 array로 나오므로 2차원의 numpy array로 형태 바꿔줘야 함\n",
    "test_y_data = train_df[\"Survived\"][train_num:].values.reshape([-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    2\n",
       "Title       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:0.5482234358787537\n",
      "cost:0.4603429436683655\n",
      "cost:0.41003790497779846\n",
      "cost:0.40239569544792175\n",
      "cost:0.4042731523513794\n",
      "cost:0.40723899006843567\n",
      "cost:0.41411906480789185\n",
      "cost:0.40675461292266846\n",
      "cost:0.4027542769908905\n",
      "cost:0.4243813455104828\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 초기화해보자! \n",
    "tf.reset_default_graph()  #  이전에는 w를 random하게 주어서 오류 안떴었는데 이제 초기값 지정해주기때문에 다시 실행하면 오류뜸\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,8], dtype=tf.float32)  \n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)  \n",
    "\n",
    "# W & b (Deep & wide)  - depth가 길면 길수록 정확한 값 안나오고 시간이 너무 오래 걸리므로 적절한 크기로 해줘야 한다. \n",
    "\n",
    "W1 = tf.get_variable(\"weight1\", \n",
    "                     shape=[8,256], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]),name=\"bias1\")\n",
    "layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2 = tf.get_variable(\"weight2\", \n",
    "                     shape=[256,256], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]),name=\"bias2\")\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", \n",
    "                     shape=[256,1], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]),name=\"bias3\")\n",
    "logit = tf.matmul(layer1,W3)+b3\n",
    "H = tf.nn.relu(logit)  # 사실 sigmoid 쓰나 softmax쓰나 같은 결과. softmax는 전체 확률로 바뀌고 sigmoid에서 가장 큰 값이 softmax에서도 가장 큰 값인건 바뀌지 않음\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,labels=Y))  # logistic 이므로 softmax아니고 sigmoid\n",
    "\n",
    "# train\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(cost)  # 이거도 자주쓰임. 크게 성능의 향상 보기엔 어렵지만 좀더 성능 좋다는게 일반적인 생각\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30  # 반복횟수\n",
    "\n",
    "batch_size = 100  # 데이터 작아서 batch의 의미 없음\n",
    "for step in range(num_of_epoch): \n",
    "    num_of_iter = int(train_num/batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x = train_x_data[batch_size*i:batch_size*(i+1)]  # x,y 100개씩 떼어오기\n",
    "        batch_y = train_y_data[batch_size*i:batch_size*(i+1)]\n",
    "        _, cost_val = sess.run([train,cost],feed_dict = {X:batch_x,\n",
    "                                                         Y:batch_y})\n",
    "    if step%3==0:\n",
    "        print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "          \n",
    "# for step in range(num_of_epoch):   \n",
    "#     _, cost_val = sess.run([train,cost],feed_dict = {X:train_x_data,\n",
    "#                                                      Y:train_y_data})\n",
    "#     if step%3000==0:\n",
    "#         print(\"cost:{}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.8379888534545898\n"
     ]
    }
   ],
   "source": [
    "predict = tf.cast(H > 0.5,dtype=tf.float32)\n",
    "# H가 예측값인데, 0.2가 나오면 1에 가까울 확률이 20%인 것, 0.8이면 1에 가까울 확률이 80%\n",
    "# 몇을 넘으면 1로 볼것인지는 마음대로 잡아도 되지만, 일반적으로 0.5 많이 한다.\n",
    "# H>0.5 하면 결과 True, False로 떨어지므로 우리가 가지고 있는 데이터 0,1로 표현해 줘야 한다.\n",
    "# 실제 데이터와 비교하기 위해 값 바꿔주는 과정 \n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean( tf.cast(correct,dtype=tf.float32) )\n",
    "# correct도 True, False로 떨어짐 -> correct를 실수값으로 다시 바꿔주는 과정\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy,feed_dict={X:test_x_data,\n",
    "                                                  Y:test_y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Embarked\"].fillna(\"S\",inplace=True)\n",
    "\n",
    "test_df[\"Title\"]=test_df[\"Name\"].str.extract(\"([A-Za-z]+)\\.\")\n",
    "# Titanic안에 Mr,Miss,Mrs,other을 각각 0,1,2,3으로 변환\n",
    "title_mapping_dict = {\"Mr\":0, \"Miss\":1,\"Mrs\":2,\"Master\":3,\"Dr\":3,\"Rev\":3,\"Col\":3,\"Major\":3,\"Mlle\":3,\n",
    "                      \"Don\":3,\"Jonkheer\":3,\"Countess\":3,\"Lady\":3,\"Mme\":3,\"Ms\":3,\"Sir\":3,\"Capt\":3}\n",
    "test_df[\"Title\"]=test_df[\"Title\"].map(title_mapping_dict)\n",
    "test_df[\"Title\"].fillna(3,inplace=True)\n",
    "test_df.drop(\"Name\",axis=1,inplace=True)  # drop: 행, 열 지울 수 있음 \n",
    "test_df.drop(\"Ticket\",axis=1,inplace=True)\n",
    "test_df.drop(\"Cabin\",axis=1,inplace=True)\n",
    "test_df.drop(\"PassengerId\",axis=1,inplace=True)\n",
    "\n",
    "## 성별 column에 대해 male=0, female=1로 변환\n",
    "sex_mapping_dict = {\"male\":0,\"female\":1}\n",
    "test_df[\"Sex\"]=test_df[\"Sex\"].map(sex_mapping_dict)\n",
    "\n",
    "## Embarked (탑승지역) 컬럼에 대해 S = 0, Q =1, C =2로 변환\n",
    "# -> 그냥 하면 NaN 2개 있기 때문에 결과 실수형으로 나옴.\n",
    "embarked_mapping_dict = {\"S\":0,\"Q\":1,\"C\":2}\n",
    "test_df[\"Embarked\"]=test_df[\"Embarked\"].map(embarked_mapping_dict)\n",
    "\n",
    "## 결측치 채우기 - age, fare\n",
    "fare_mean = train_df.groupby(\"Pclass\")[\"Fare\"].mean()\n",
    "#plt.boxplot(test_df[\"Fare\"].dropna(how=\"any\",inplace=False))\n",
    "#test_df[\"Fare\"].fillna(fare_mean)\n",
    "\n",
    "fare_mean = test_df.groupby(\"Pclass\")[\"Fare\"].mean()\n",
    "a = test_df[test_df[\"Pclass\"]==1][\"Fare\"].fillna(fare_mean[1])\n",
    "b = test_df[test_df[\"Pclass\"]==2][\"Fare\"].fillna(fare_mean[2])\n",
    "c = test_df[test_df[\"Pclass\"]==3][\"Fare\"].fillna(fare_mean[3])\n",
    "result_series = pd.concat([a,b,c])\n",
    "test_df[\"Fare\"]=result_series.sort_index()\n",
    "\n",
    "age_mean = test_df.groupby(\"Title\")[\"Age\"].mean()\n",
    "a = test_df[test_df[\"Title\"]==0][\"Age\"].fillna(age_mean[0])\n",
    "b = test_df[test_df[\"Title\"]==1][\"Age\"].fillna(age_mean[1])\n",
    "c = test_df[test_df[\"Title\"]==2][\"Age\"].fillna(age_mean[2])\n",
    "d = test_df[test_df[\"Title\"]==3][\"Age\"].fillna(age_mean[3])\n",
    "result_series = pd.concat([a,b,c,d])\n",
    "test_df[\"Age\"]=result_series.sort_index()\n",
    "\n",
    "\n",
    "## Age에 대해서 binning 처리 (구간으로 나눠서 숫자 mapping시켜서 숫자 이용하기)\n",
    "# 고려해야 할 사항 -> 간격 어떻게 설정할거냐?\n",
    "test_df.loc[test_df[\"Age\"]<=20,\"Age\"]=0\n",
    "test_df.loc[(test_df[\"Age\"]>20)&(test_df[\"Age\"]<=40),\"Age\"]=1\n",
    "test_df.loc[(test_df[\"Age\"]>40)&(test_df[\"Age\"]<=60),\"Age\"]=2\n",
    "test_df.loc[test_df[\"Age\"]>60,\"Age\"]=3\n",
    "\n",
    "# Fare도 binning 처리 해보자\n",
    "# test_df.loc[train_df[\"Fare\"]<=100,\"Fare\"]=0\n",
    "# test_df.loc[(test_df[\"Fare\"]>100)&(test_df[\"Fare\"]<=200),\"Fare\"]=1\n",
    "# test_df.loc[(test_df[\"Fare\"]>200)&(test_df[\"Fare\"]<=300),\"Fare\"]=2\n",
    "# test_df.loc[(test_df[\"Fare\"]>300),\"Fare\"]=3\n",
    "\n",
    "# # Fare도 binning 처리 해보자\n",
    "test_df.loc[test_df[\"Fare\"]<=14,\"Fare\"]=0\n",
    "test_df.loc[(test_df[\"Fare\"]>14)&(test_df[\"Fare\"]<=65),\"Fare\"]=1\n",
    "test_df.loc[(test_df[\"Fare\"]>65),\"Fare\"]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = test_df.values  # 컬럼삭제, 원본유지 \n",
    "\n",
    "result_H = sess.run(H, feed_dict={X:x_data})      \n",
    "\n",
    "predict = tf.cast(result_H > 0.5,dtype=tf.int32)\n",
    "result = sess.run(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         0\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = pd.read_csv(\"./data/titanic/test.csv\")[\"PassengerId\"]\n",
    "\n",
    "# concat(): 연결 -> 연결할 것을 list 형태로\n",
    "s1 = pd.DataFrame(test_id)\n",
    "s2 = pd.DataFrame(result)\n",
    "result = pd.concat([s1,s2],axis=1)\n",
    "#result = result.rename({'Survived':'0'},axis='columns')\n",
    "result.columns=['PassengerId','Survived']\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./data/titanic/submission_deep.csv',\n",
    "                 sep=',',\n",
    "                 na_rep='NaN', \n",
    "                 columns = ['PassengerId','Survived'], # columns to write\n",
    "                 index = False) # do not write index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = train_df.drop(\"Survived\",axis=1,inplace=False).values  # 컬럼삭제, 원본유지 \n",
    "y_data = train_df[\"Survived\"].values.reshape([-1,1])  # 1차원의 array로 나오므로 2차원의 numpy array로 형태 바꿔줘야 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:1.7707507610321045\n",
      "cost:0.37824931740760803\n",
      "cost:0.34818485379219055\n",
      "cost:0.3582134246826172\n",
      "cost:0.3402332067489624\n",
      "cost:0.3368334472179413\n",
      "cost:0.3369526267051697\n",
      "cost:0.3380812704563141\n",
      "cost:0.3254116475582123\n",
      "cost:0.3379199206829071\n"
     ]
    }
   ],
   "source": [
    "# 그래프를 초기화해보자! \n",
    "tf.reset_default_graph() \n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,8], dtype=tf.float32)  # 28*28 = 784\n",
    "Y = tf.placeholder(shape=[None,1], dtype=tf.float32)  # 0-9\n",
    "keep_rate = tf.placeholder(dtype=tf.float32) # 값 1개 scalar값이므로 shape 안줘도 된다. -> drop out 비율\n",
    "    # cpu_env에서는 tensorflow 버전 gpu랑 달라서 dout_rate 말고 keep_rate 쓰자. keep_prob로 써야 함  \n",
    "\n",
    "# W & b (Deep & wide) \n",
    "W1 = tf.get_variable(\"weight1\", \n",
    "                     shape=[8,100], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([100]),name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1,keep_prob=keep_rate) # 256개  output을 다 뽑아내지 않겠다. node를 아예 삭제하는게 아니라 기능을 상실시키는 것\n",
    "                                         # rate=0 하면 다 살아있는거   0.3하면 30% 죽이는거 -> 다음으로 30프로 죽여서 넘기겠다.\n",
    "\n",
    "# W2 = tf.get_variable(\"weight2\", \n",
    "#                      shape=[256,256], \n",
    "#                      initializer = tf.contrib.layers.xavier_initializer())\n",
    "# b2 = tf.Variable(tf.random_normal([256]),name=\"bias2\")\n",
    "# _layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "# layer2 = tf.nn.dropout(_layer2,keep_prob=keep_rate) \n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", \n",
    "                     shape=[100,1], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([1]),name=\"bias3\")  # 맨 마지막에는 dropout해주지 않는다. -> 다 넘겨야 하므로\n",
    "logit = tf.matmul(layer1,W3)+b3\n",
    "H = tf.nn.relu(logit)  \n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,labels=Y))  \n",
    "\n",
    "# train\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.05).minimize(cost)  # 이거도 자주쓰임. 크게 성능의 향상 보기엔 어렵지만 좀더 성능 좋다는게 일반적인 생각\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 5000  # 반복횟수\n",
    "# batch_size = 100\n",
    "\n",
    "# for step in range(num_of_epoch): \n",
    "#     num_of_iter = int(train_num/batch_size)\n",
    "#     cost_val = 0\n",
    "    \n",
    "#     for i in range(num_of_iter):\n",
    "#         batch_x = train_x_data[batch_size*i:batch_size*(i+1)]  # x,y 100개씩 떼어오기\n",
    "#         batch_y = train_y_data[batch_size*i:batch_size*(i+1)]\n",
    "#         _, cost_val = sess.run([train,cost],feed_dict = {X:batch_x,\n",
    "#                                                          Y:batch_y,\n",
    "#                                                          keep_rate:0.6}) # 30% 끄고 학습해라\n",
    "#     if step%3==0:\n",
    "#         print(\"cost:{}\".format(cost_val))\n",
    "\n",
    "for step in range(num_of_epoch):   \n",
    "    _, cost_val = sess.run([train,cost],feed_dict = {X:x_data,\n",
    "                                                     Y:y_data,\n",
    "                                                    keep_rate:0.7})\n",
    "    if step%500==0:\n",
    "        print(\"cost:{}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.8435754179954529\n"
     ]
    }
   ],
   "source": [
    "predict = tf.cast(H > 0.5,dtype=tf.float32)\n",
    "# H가 예측값인데, 0.2가 나오면 1에 가까울 확률이 20%인 것, 0.8이면 1에 가까울 확률이 80%\n",
    "# 몇을 넘으면 1로 볼것인지는 마음대로 잡아도 되지만, 일반적으로 0.5 많이 한다.\n",
    "# H>0.5 하면 결과 True, False로 떨어지므로 우리가 가지고 있는 데이터 0,1로 표현해 줘야 한다.\n",
    "# 실제 데이터와 비교하기 위해 값 바꿔주는 과정 \n",
    "correct = tf.equal(predict, Y)\n",
    "accuracy = tf.reduce_mean( tf.cast(correct,dtype=tf.float32) )\n",
    "# correct도 True, False로 떨어짐 -> correct를 실수값으로 다시 바꿔주는 과정\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy,feed_dict={X:test_x_data,\n",
    "                                                  Y:test_y_data,\n",
    "                                                  keep_rate:0.7})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 진짜 test\n",
    "x_data = test_df.values  # 컬럼삭제, 원본유지 \n",
    "\n",
    "result_H = sess.run(H, feed_dict={X:x_data,\n",
    "                                 keep_rate:0.7})      \n",
    "\n",
    "predict = tf.cast(result_H > 0.5,dtype=tf.int32)\n",
    "result = sess.run(predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>1306</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>1309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived\n",
       "0            892         0\n",
       "1            893         0\n",
       "2            894         0\n",
       "3            895         0\n",
       "4            896         0\n",
       "..           ...       ...\n",
       "413         1305         0\n",
       "414         1306         1\n",
       "415         1307         0\n",
       "416         1308         0\n",
       "417         1309         1\n",
       "\n",
       "[418 rows x 2 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = pd.read_csv(\"./data/titanic/test.csv\")[\"PassengerId\"]\n",
    "\n",
    "# concat(): 연결 -> 연결할 것을 list 형태로\n",
    "s1 = pd.DataFrame(test_id)\n",
    "s2 = pd.DataFrame(result)\n",
    "result = pd.concat([s1,s2],axis=1)\n",
    "#result = result.rename({'Survived':'0'},axis='columns')\n",
    "result.columns=['PassengerId','Survived']\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('./data/titanic/submission_deep_dropout.csv',\n",
    "                 sep=',',\n",
    "                 na_rep='NaN', \n",
    "                 columns = ['PassengerId','Survived'], # columns to write\n",
    "                 index = False) # do not write index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
