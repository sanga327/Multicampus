{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## kaggle - dataset에서 mnist검색\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import mglearn \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = pd.read_csv(\"./data/digit-recognizer/train.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은:2.346472978591919\n",
      "Cost값은:0.49307265877723694\n",
      "Cost값은:0.431395024061203\n",
      "Cost값은:0.4014136493206024\n",
      "Cost값은:0.3832317292690277\n",
      "Cost값은:0.37106460332870483\n",
      "Cost값은:0.36240267753601074\n",
      "Cost값은:0.3560386598110199\n",
      "Cost값은:0.35131314396858215\n",
      "Cost값은:0.3477976322174072\n"
     ]
    }
   ],
   "source": [
    "##################################################################################################\n",
    "# train data와 test data 생성 \n",
    "# 정규화 작업\n",
    "scaler= MinMaxScaler()\n",
    "train_num = int(data_df.shape[0]*0.8) \n",
    "# scaler.data_max_  # 가지고있는 데이터의 최대값\n",
    "# scaler.data_min_  # 최대, 최소값 가지고 scaling\n",
    "x_data = data.drop(\"label\",axis=1,inplace=False)\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "\n",
    "# 데이터 분할해 x data 생성 - 80:20\n",
    "train_x_data = x_data[:train_num]  # nparray에서 자른 값 ->  뒤의 값이 exclusive 해서 16000개\n",
    "test_x_data = x_data[train_num:]\n",
    "\n",
    "# 학습용, 테스트용 y data 생성 -> one hot encoding\n",
    "# one hot encoding으로 전환하는 방법 2가지\n",
    "\n",
    "sess = tf.Session()\n",
    "train_y_data = sess.run(tf.one_hot(data_df.loc[:train_num-1,\"label\"], 10)) # 원래 1차원 자료가 one-hot encoding 적용하면 2차원 자료가 된다.\n",
    "# sess.run(tf.one_hot(bmi_df.loc[:train_num-1,\"label\"], 3)).shape # data frame이라 loc 사용하면 뒤부분 inclusive하다 -> train_num -1 빼줘야 함! \n",
    "test_y_data = sess.run(tf.one_hot(data_df.loc[train_num:,\"label\"], 10))\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([784,10]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) \n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "# 학습\n",
    "train_epoch = 300  # 전체를 30번 할거다 (100개씩 잘라서 전체 도는거를 30번 하겠다.)\n",
    "batch_size = 100 # 한번에 몇개를 학습할거니? 일반적으로 100개씩 하면 적당함\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(train_num/batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)    \n",
    "        batch_x = train_x_data[batch_size*i:batch_size*(i+1)]\n",
    "        batch_y = train_y_data[batch_size*i:batch_size*(i+1)]\n",
    "        \n",
    "        _, cost_val = sess.run([train,cost],\n",
    "                              feed_dict={X:batch_x,\n",
    "                                        Y:batch_y})\n",
    "    if step%30==0:\n",
    "        print(\"Cost값은:{}\".format(cost_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도는:0.9169047474861145\n"
     ]
    }
   ],
   "source": [
    "# 학습이 종료되었으니 정확도를 측정하자! \n",
    "predict = tf.argmax(H,axis=1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype = tf.float32))\n",
    "\n",
    "print(\"정확도는:{}\".format(sess.run(accuracy, feed_dict={X:test_x_data,\n",
    "                                                    Y:test_y_data})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1,2) (784,) (1,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-7e0e2b0d5ad6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# MinMax scaler가 min, max값 가지고 있다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mprediction_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m170\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#sess.run(H,feed_dict={X:prediction_data})\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    412\u001b[0m                         force_all_finite=\"allow-nan\")\n\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1,2) (784,) (1,2) "
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "# prediction_data = [[187,78]]\n",
    "# 예측하기 위해서 다시 scaling한 값 넣어줘야 한다.\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform([[170,70]])\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})[0]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle에 제출해 보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost값은:1.4366788864135742\n",
      "Cost값은:0.23139512538909912\n",
      "Cost값은:0.19904983043670654\n",
      "Cost값은:0.18799999356269836\n",
      "Cost값은:0.1797056347131729\n",
      "Cost값은:0.17264489829540253\n",
      "Cost값은:0.16695469617843628\n",
      "Cost값은:0.16256456077098846\n",
      "Cost값은:0.15922415256500244\n",
      "Cost값은:0.1566733866930008\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전체로 학습하자\n",
    "# 정규화 작업\n",
    "scaler= MinMaxScaler()\n",
    "\n",
    "x_data = data.drop(\"label\",axis=1,inplace=False)\n",
    "x_data = scaler.fit_transform(x_data)\n",
    "\n",
    "sess = tf.Session()\n",
    "y_data = sess.run(tf.one_hot(data_df[\"label\"], 10))\n",
    "\n",
    "#################################################################################################\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784],dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10],dtype=tf.float32)\n",
    "\n",
    "# W, b\n",
    "W = tf.Variable(tf.random_normal([784,10]),name=\"weight\")\n",
    "b = tf.Variable(tf.random_normal([10]),name=\"bias\")  # 1차원으로 3개\n",
    "\n",
    "# H\n",
    "logit = tf.matmul(X,W)+b \n",
    "H = tf.nn.softmax(logit) \n",
    "\n",
    "# cost function\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,   # version2로 해야 정확\n",
    "                                                                labels=Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# session\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "# 학습\n",
    "train_epoch = 300  # 전체를 30번 할거다 (100개씩 잘라서 전체 도는거를 30번 하겠다.)\n",
    "batch_size = 100 # 한번에 몇개를 학습할거니? 일반적으로 100개씩 하면 적당함\n",
    "\n",
    "for step in range(train_epoch):\n",
    "    num_of_iter = int(x_data.shape[0]/batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        #batch_x, batch_y = mnist.train.next_batch(batch_size)    \n",
    "        batch_x = x_data[batch_size*i:batch_size*(i+1)]\n",
    "        batch_y = y_data[batch_size*i:batch_size*(i+1)]\n",
    "        \n",
    "        _, cost_val = sess.run([train,cost],\n",
    "                              feed_dict={X:batch_x,\n",
    "                                         Y:batch_y})\n",
    "    if step%30==0:\n",
    "        print(\"Cost값은:{}\".format(cost_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 진짜 test 파일로 돌려보자!!\n",
    "\n",
    "test_data = pd.read_csv(\"./data/digit-recognizer/test.csv\")\n",
    "#test_data.shape\n",
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform(test_data)\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame()\n",
    "my_df[\"ImageId\"] = range(1,test_data.shape[0]+1)\n",
    "my_df[\"Label\"] = result\n",
    "my_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.to_csv('./data/digit-recognizer/mnist.csv',\n",
    "                 sep=',',\n",
    "                 na_rep='NaN', \n",
    "                 columns = ['ImageId','Label'], # columns to write\n",
    "                 index = False) # do not write index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 내 데이터를 이용해서 해보자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import PIL.Image as img\n",
    "import numpy as np\n",
    "\n",
    "# Read image\n",
    "im = img.open(\"./data/digit-recognizer/nine.png\").convert('L')\n",
    "im = im.resize([28,28])\n",
    "# Display image\n",
    "plt.imshow(im, cmap='gray')\n",
    " \n",
    "# Fetch image pixel data to numpy array\n",
    "pix = np.array(im)\n",
    "\n",
    "pix = 255-pix\n",
    "pix = pix.reshape([1,-1])\n",
    "#pix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# MinMax scaler가 min, max값 가지고 있다.\n",
    "prediction_data = scaler.transform(pix)\n",
    "\n",
    "#sess.run(H,feed_dict={X:prediction_data})\n",
    "result = sess.run(tf.argmax(H,1), feed_dict={X:prediction_data})\n",
    "#result\n",
    "result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
