{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN (Convolutional Neural Network) : 합성곱 신경망\n",
    "\n",
    "#### FC Layer (Fully Connected Layer)\n",
    "- 이전 layer의 모든 node가 다음 layer의 모든 node에 연결되어 학습되는 layer 구조\n",
    "- 다른 말로 Dense Layer라고도 한다.\n",
    "- 지금까지 우리가 작업한 신경망은 모두 FC Layer를 이용하고 있음 \n",
    "- 지금까지 우리가 배운 내용 (모든 레이어가 연결되어 그 다음 입력값으로 입력되는 구조)  \n",
    "\n",
    "#### FC Layer의 특징: MNIST의 예제처럼 입력 데이터가 1차원으로 한정된다.\n",
    "( 한사람의 데이터가 1차원으로 표현 -> 여러사람이라 2차원 형태였음)   \n",
    "(image도 흑백이라 2차원 자료)  \n",
    "(즉, 각각의 이미지가 1차원으로 표현되어야 한다.)\n",
    "- 그래서 2차원 이미지를 우리가 1차원으로 변환시켜서 사용한 것\n",
    "- 우리가 사용한 MNIST 예제는 상당히 간단한 이미지 학습, 예측 예제  \n",
    "\n",
    "#### FC Layer의 문제  \n",
    "- 이미지 학습의 가장 큰 문제는 이미지가 살짝 휘어있거나 크기가 제각각이거나 변형이 조금만 생겨도 학습이 힘들어진다. \n",
    "- 이런 경우에는 training data가 굉장히 많이 필요하고 추가적으로 학습할 때 많은 시간을 요구하게 된다. \n",
    "- 고민하면서 방법을 연구하기 시작\n",
    "- 사람이 학습하는 방식을 모델링함 -> 특징을 가지고 학습\n",
    "- 찾아낸 방법: 이미지의 픽셀값을 그대로 입력하는게 아니라 이미지를 대표하는 특징을 도출해서 신경망에 여러개 넣어서 학습하는 방식  \n",
    "\n",
    "#### CNN\n",
    "- 1장의 컬러사진은 width, height, color(depth) 3차원으로 표현\n",
    "- 여러장의 사진이 사용되기 때문에 입력 데이터는 4차원으로 표현 \n",
    "- 실제 이미지 1장은 3차원이고 이걸 flatten 시켜서 1차원으로 표현해야 한다.\n",
    "- 크기를 조절해야 하기 때문에 공간에 대한 데이터를 유실할 우려가 있다. \n",
    "- 이런 데이터 유실때문에 학습과 예측에 문제가 발생하게 된다.  \n",
    "\n",
    "#### 공간 데이터의 유실을 없애고 이미지의 특성을 추출해서 학습이 용이하게 만드는 방식 => CNN \n",
    "- 이렇게 만든 데이터로 FC Layer에 넣는 것\n",
    "- CNN은 우리가 배운거 하기 전에 끼워넣는 단계 \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 코드로 알아보자! \n",
    "### 사용되는 함수부터 알아보자. \n",
    "### sample CNN\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image의 shape : (1, 3, 3, 1)\n",
      "weight(filter)의 shape : (2, 2, 1, 3)\n",
      "conv2d의 shape : Tensor(\"Conv2D_1:0\", shape=(1, 2, 2, 3), dtype=float32)\n",
      "pool의 shape : (1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 입력 데이터의 형식: 3*3*1 (width*height*color) 이미지 1개를 이용\n",
    "# 입력 데이터 -> 이미지 개수, width, height, color 수 -> (1,3,3,1)\n",
    "# 총 9개의 데이터 사용(1~9)\n",
    "image = np.array([[[[1],[2],[3]],\n",
    "                   [[4],[5],[6]],\n",
    "                   [[7],[8],[9]]]], dtype=np.float32)\n",
    "print(\"image의 shape : {}\".format(image.shape )) # (1, 3, 3, 1) 마지막 값은 []괄호 안의 값 몇 개냐\n",
    "\n",
    "# Activation map을 위한 filter를 정의 (width, height, color, filter 개수)\n",
    "# filter (2,2,1,3) : 2행 2열, depth(color 개수)는 1, filter개수는 3  \n",
    "weight = np.array([[[[1,10,-1]],[[2,10,-1]]],\n",
    "                   [[[1,10,-1]],[[1,10,-1]]]])\n",
    "print(\"weight(filter)의 shape : {}\".format(weight.shape))\n",
    "\n",
    "# stride = 1 (가로, 세로를 1씩 움직여라)\n",
    "conv2d = tf.nn.conv2d(image, weight, strides=[1,1,1,1], padding=\"VALID\")   \n",
    "    # padding=\"VALID\": 패딩하지 마라(사이즈 줄이겠다)  / padding=\"SAME\" 하면 차원 같게 (패딩처리 해라)\n",
    "    # [1,가로, 세로,1]  \n",
    "    # stride크기는 가로 세로 같게 잡는것이 좋음. # 양 옆의 1,1은 4차원 만들어주는 더미변수일 뿐\n",
    "print(\"conv2d의 shape : {}\".format(conv2d))        # (1, 2, 2, 3): (2,2,3)이 1장 있다 \n",
    "sess = tf.Session()\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# pooling layer \n",
    "pool = tf.nn.max_pool(conv2d, ksize=[1,2,2,1],   # 2,2 크기의 빈칸 \n",
    "                      strides=[1,1,1,1], padding=\"SAME\") # ksize: kernel size  # 앞뒤값은 더미. 가운데가 중요!\n",
    "        # SAME의 의미는 padding을 상하좌우에 붙인다는게 아니라 출력 크기가 처음과 같게 해주도록 붙여준다는 것\n",
    "print(\"pool의 shape : {}\".format(pool.shape))   # (1, 2, 2, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "conv2d의 shape : (1, 14, 14, 5)\n",
      "conv2d_img의 shape : (5, 14, 14, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d8aaf25400>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convolution 결과 이미지가 원본 이미지에 비해 어떻게 다른지 눈으로 확인해보자!\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# data loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "img = mnist.train.images[0].reshape(28,28)\n",
    "plt.imshow(img, cmap=\"Greys\")\n",
    "\n",
    "# 해당 이미지를 convolution 처리를 해 보자!\n",
    "# 입력 데이터의 형식: 3*3*1 (width*height*color) \n",
    "img = img.reshape(-1,28,28,1)  # 맨 앞은 이미지 개수이므로 1이라고 써도 되지만 -1쓰면 뒤에거 채우고 나머지 다 이미지 개수로 채움\n",
    "# Activation map을 위한 filter를 정의 (width, height, color, filter 개수)\n",
    "W = tf.Variable(tf.random_normal([3,3,1,5]),name=\"filter1\")\n",
    "conv2d = tf.nn.conv2d(img, W, strides=[1,2,2,1], padding=\"SAME\") \n",
    "    # strides가 1일 경우, padding=\"SAME\" 하면 원래 크기와 같게 나오지만, ->28,28\n",
    "    # strides가 2일 경우, padding=\"SAME\" 하면 원래 크기의 절반 크기로 출력됨 -> 14,14\n",
    "print(\"conv2d의 shape : {}\".format(conv2d.shape))   # (1,14,14,5)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())  # 앞에서 랜덤으로 잡는 거 있었으므로 초기화 시켜줘야 한다.\n",
    "conv2d = sess.run(conv2d)\n",
    "\n",
    "# (1,14,14,5) -> (14,14)크기의 5장이 1개 있다\n",
    "# (5,14,14,1) -> (14,14,1)크기의 5장이 있다 \n",
    "# -> 같은 말로 해석 가능\n",
    "# 뒷부분 3장이 이미지 하나를 나타내는 말이므로 \n",
    "\n",
    "# 이미지를 표현하기 위해서 축을 변환해보자!\n",
    "# (1,14,14,5) -> (5,14,14,1) \n",
    "conv2d_img = np.swapaxes(conv2d,0,3)\n",
    "print(\"conv2d_img의 shape : {}\".format(conv2d_img.shape))   \n",
    "\n",
    "plt.imshow(conv2d_img[0].reshape(14,14), cmap=\"Greys\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorflow-MNIST with CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "cost:0.2335168868303299\n",
      "cost:0.1703042984008789\n",
      "cost:0.10083776712417603\n",
      "cost:0.20362286269664764\n",
      "cost:0.15158894658088684\n",
      "cost:0.2773580849170685\n",
      "cost:0.1130962073802948\n",
      "cost:0.372658908367157\n",
      "cost:0.10209430754184723\n",
      "cost:0.05403153598308563\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# 그래프를 초기화해보자! \n",
    "tf.reset_default_graph() \n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\",one_hot=True)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "keep_rate = tf.placeholder(dtype=tf.float32) # drop out 비율\n",
    "\n",
    "# Convolution Layer\n",
    "x_img = tf.reshape(X,[-1,28,28,1])  # -1: 몇장인지 모름    # convolution하려면 무조건 4차원이어야 함!\n",
    "F1 = tf.Variable(tf.random_normal(shape=[3,3,1,32]))  #  32개의 filter map\n",
    "    # 여기서는 자비에르초기법 하는거 아님. W의 초기값을 랜덤으로 받는다는 건데 그건 머신러닝때. 지금은 filter를 랜덤으로 잡는 과정이므로 랜덤해야한다.\n",
    "L1 = tf.nn.conv2d(x_img, F1, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L1 = tf.nn.relu(L1)  # convolution 하고 relu 해줘야 함(값 너무 커지지 않게)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "# -> 14*14 크기가 32개 나옴\n",
    "\n",
    "F2 = tf.Variable(tf.random_normal(shape=[3,3,32,64]))  # 32: 앞에서 나오는 channel 수\n",
    "    # 3*3 크기의 32 depth를 64번 filter하겠다\n",
    "L2 = tf.nn.conv2d(L1, F2, strides=[1,1,1,1], padding=\"SAME\")\n",
    "L2 = tf.nn.relu(L2)  \n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")    \n",
    "# -> 7*7 크기가 64개 나옴  \n",
    "\n",
    "\n",
    "# 이렇게 만든 데이터를 FC Layer에 넣어서 학습해야 한다.\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W1 = tf.get_variable(\"weight1\", shape=[7*7*64,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "############################################################################\n",
    "\n",
    "b1 = tf.Variable(tf.random_normal([256]),name=\"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W1)+b1)\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_rate) # 256개  output을 다 뽑아내지 않겠다. node를 아예 삭제하는게 아니라 기능을 상실시키는 것\n",
    "                                         # rate=0 하면 다 살아있는거   0.3하면 30% 죽이는거 -> 다음으로 30프로 죽여서 넘기겠다.\n",
    "     # drop_rate가 cpu_env에서는 keep_rate\n",
    "W2 = tf.get_variable(\"weight2\", \n",
    "                     shape=[256,256], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]),name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W2)+b2)\n",
    "layer2 = tf.nn.dropout(_layer2,keep_prob=keep_rate) \n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", \n",
    "                     shape=[256,10], \n",
    "                     initializer = tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]),name=\"bias3\")  # 맨 마지막에는 dropout해주지 않는다. -> 다 넘겨야 하므로\n",
    "logit = tf.matmul(layer2,W3)+b3\n",
    "H = tf.nn.relu(logit)  \n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logit,labels=Y))  \n",
    "\n",
    "# train\n",
    "#train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)  # 이거도 자주쓰임. 크게 성능의 향상 보기엔 어렵지만 좀더 성능 좋다는게 일반적인 생각\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch =50  # 반복횟수\n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch): \n",
    "    num_of_iter = int(mnist.train.num_examples/batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)  # x,y 100개씩 떼어오기\n",
    "        _, cost_val = sess.run([train,cost],feed_dict = {X:batch_x,\n",
    "                                                         Y:batch_y,\n",
    "                                                         keep_rate:0.7}) # 30% 끄고 학습해라\n",
    "    if step%5==0:\n",
    "        print(\"cost:{}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:0.9794999957084656\n"
     ]
    }
   ],
   "source": [
    "# accuracy 측정\n",
    "predict = tf.argmax(H,1)\n",
    "correct = tf.equal(predict, tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, dtype=tf.float32))\n",
    "\n",
    "print(\"정확도:{}\".format(sess.run(accuracy, feed_dict={X:mnist.test.images,\n",
    "                                                       Y:mnist.test.labels,\n",
    "                                                       keep_rate:1})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/mnist\\t10k-labels-idx1-ubyte.gz\n",
      "Cost : 0.47341403365135193\n",
      "Cost : 0.3523519039154053\n",
      "Cost : 0.29518187046051025\n",
      "Cost : 0.16579708456993103\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d6a186b0e601>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     86\u001b[0m         _, cost_val = sess.run([train,cost], feed_dict={X:batch_x,\n\u001b[0;32m     87\u001b[0m                                                        \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                                                        keep_rate:0.7})\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    893\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 895\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    896\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1126\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1128\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1129\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1344\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1345\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\cpu_env\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1329\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#### 혜준이거##########\n",
    "# tensorflow-MNIST with CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "# Data Loading\n",
    "mnist = input_data.read_data_sets(\"./data/mnist\", one_hot=True)\n",
    "\n",
    "# Graph 초기화\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Placeholder\n",
    "X = tf.placeholder(shape=[None,784], dtype=tf.float32)\n",
    "Y = tf.placeholder(shape=[None,10], dtype=tf.float32)\n",
    "keep_rate = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "# Convolution Layer\n",
    "x_img = tf.reshape(X,[-1,28,28,1]) # X를 이모양으로 바꿔\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32])) # 3,3,1에 filter 32개 \n",
    "L1 = tf.nn.conv2d(x_img, W1, strides=[1,1,1,1], padding=\"SAME\") \n",
    "L1 = tf.nn.relu(L1) # convolution을 하면 값이 커지거나 작아지기때문에 relu를 해줍니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\") # pooling도 여기서는 해줄게요\n",
    "# stride를 2로 잡고 padding을 해주었으니 size가 반으로 줄었겠죠 \n",
    "# 결과적으로 [None,14,14,32]\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64])) # (새필터가로, 새필터세로, 이전에필터갯수, 새로운필터갯수)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding=\"SAME\") \n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding=\"SAME\")\n",
    "# stride를 2로 잡고 다시 padding을 해주었으니 size가 또 반으로 줄었겠죠\n",
    "# 결과적으로 [None,7,7,64]\n",
    "\n",
    "\n",
    "# 이렇게 만든 데이터를 FC Layer에 넣어서 학습해야 해요!\n",
    "L2 = tf.reshape(L2,[-1,7*7*64])\n",
    "\n",
    "W3 = tf.get_variable(\"weight3\", shape=[7*7*64,256],\n",
    "                    initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]), name= \"bias1\")\n",
    "_layer1 = tf.nn.relu(tf.matmul(L2,W3) + b1) # 이렇게 하면 256개가 나옴\n",
    "layer1 = tf.nn.dropout(_layer1, keep_prob=keep_rate) # 위의 256개의 노드의 기능을 상실시키겠다.30%를 죽여서 넘기겠다.\n",
    "# cpu_env에서는 rate가 아니라 keep_prob으로 keep_rate는 남기고 싶은 퍼센트를 넣어주면 된다\n",
    "\n",
    "\n",
    "W4 = tf.get_variable(\"weight4\", shape=[256,256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer()) # 초기화 방법       \n",
    "b2 = tf.Variable(tf.random_normal([256]), name=\"bias2\")\n",
    "_layer2 = tf.nn.relu(tf.matmul(layer1,W4) + b2)\n",
    "layer2 = tf.nn.dropout(_layer2, keep_prob=keep_rate)\n",
    "\n",
    "W5 = tf.get_variable(\"weight5\", shape=[256,10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer()) # 초기화 방법      \n",
    "b3 = tf.Variable(tf.random_normal([10]), name=\"bias3\")\n",
    "\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer2, W5) + b3\n",
    "H = tf.nn.relu(logit)\n",
    "\n",
    "\n",
    "# cost\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = logit,\n",
    "                                                              labels = Y))\n",
    "\n",
    "# train\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "# Adamoptimizer가 더 좋은 성능을 가진 함수이다!!!\n",
    "\n",
    "# session, 초기화 \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "num_of_epoch = 30 \n",
    "batch_size = 100\n",
    "\n",
    "for step in range(num_of_epoch):\n",
    "    num_of_iter = int(mnist.train.num_examples / batch_size)\n",
    "    cost_val = 0\n",
    "    \n",
    "    for i in range(num_of_iter):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([train,cost], feed_dict={X:batch_x,\n",
    "                                                       Y:batch_y,\n",
    "                                                       keep_rate:0.7})\n",
    "        \n",
    "    if step % 3 == 0:\n",
    "        print(\"Cost : {}\".format(cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "[CPU_ENV]",
   "language": "python",
   "name": "cpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
